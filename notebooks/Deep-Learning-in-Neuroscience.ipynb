{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"ee-notebook-buttons\" align=\"left\"><td>\n",
    "<a target=\"_blank\"  href=\"https://colab.research.google.com/github/walkerlab/FENS-2022/blob/main/notebooks/Deep-Learning-in-Neuroscience.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /> Run in Google Colab</a>\n",
    "</td><td>\n",
    "<a target=\"_blank\"  href=\"https://github.com/walkerlab/FENS-2022/blob/main/notebooks/Deep-Learning-in-Neuroscience.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /> View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp0SO4gr2D7w"
   },
   "source": [
    "# Welcome to the Hands-on Workshop on Machine Learning by Edgar Y. Walker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Jupyter notebook accompanying the hands-on workshop on machine learning, taught as part of the 2022 [FENS Summer School on 'Artificial and natural computations for sensory perception: what is the link?'](https://www.fens.org/news-activities/fens-and-societies-calendar/training-event/fens-summer-school-on-artificial-and-natural-computations-for-sensory-perception-what-is-the-link). This notebook as well as any other relevant information can be found in the [GitHub repository](https://github.com/walkerlab/FENS-2022)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, we will learn how deep learning is leveraged in neuroscience, specifically in building models of neuronal responses to complex sensory inputs such as natural images as part of **system identification**.\n",
    "We will get our hands dirty by taking real neuronal responses recorded from mouse primary visual cortex (V1) as the mouse observed natural images, developing models to predict these responses from the images. \n",
    "\n",
    "By the end of this workshop, you will gain basic familiarity in developing deep learning models to predict responses of 1000s of neurons to natural images, ready for you to embark on group projects!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>NOTE: Please run this part at the very beginning of the first session!</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to dive in and learn how deep learning is used in neuroscience and get your first neural predictive model trained, we need to install some prerequisite packages and download some neuronal data! Downloading the library and dataset can take a few to 10s of minutes, depending on the network condition, so it is best done at the very beginning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to primarily use [PyTorch](https://pytorch.org) to build, train and evaluate our deep learning models (note - this tutorial assumes some familiarity with PyTorch already, the basics are not covered; if basics are unfamiliar, refer to the official [PyTorch Tutorials](https://pytorch.org/tutorials/)). PyTorch comes standard and installed in Colab environments, alongside with other scientific computing essentials like `numpy`, `matplotlib` and `scipy`.\n",
    "\n",
    "In order to handle the dataset containing neuronal activities, we are going to make our life easier by using a few existing libraries, collected under [FENS-2022](https://github.com/walkerlab/FENS-2022) prepared by [Walker Lab](https://eywalkerlab.com). This library has a dependency on [neuralpredictors](https://github.com/sinzlab/neuralpredictors), which is a collection of PyTorch modules, tools and other utilities that would prove helpful to train networks to predict neuronal responses prepared by [Sinz Lab](https://sinzlab.org/).\n",
    "\n",
    "Let's go ahead and install this inside the Colab environment (you can skip this if you are running this inside a Docker environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "m7dJ_i-tSPEq",
    "outputId": "bdc3f3f8-e451-4bd3-83d5-3f126b88f431"
   },
   "outputs": [],
   "source": [
    "# Clone and install the FENS package\n",
    "!git clone https://github.com/walkerlab/FENS-2022.git\n",
    "!pip3 install -e FENS-2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the dataset made available from our recent work [Lurz et al. ICLR 2021](https://github.com/sinzlab/Lurz_2020_code) in which we predict responses of mouse visual cortex to natural images. \n",
    "\n",
    "The dataset can take a few minutes to download and unzip, so please be sure to **run the following at the very beginning of the session!** We are going to first spend some time learning the basics of neuroscience and it would be best that you let the download take place during that time!\n",
    "We are also going to be exploring pre-trained networks from the work. We will go ahead and download the trained network parameters at the same time.\n",
    "\n",
    "To download the data, simply execute the following cell, and let it run till completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsNehEZlTSL4",
    "outputId": "8e2984ad-9f32-4dfd-b8b7-4536f2e53823"
   },
   "outputs": [],
   "source": [
    "# download the dataset\n",
    "!wget -nc \"https://onedrive.live.com/download?cid=06D44059794C5B46&resid=6D44059794C5B46%21121992&authkey=AHJVfxtvAASasjQ\" -O dataset.zip\n",
    "\n",
    "# Unzip\n",
    "!unzip -nq 'dataset.zip'\n",
    "\n",
    "# get trained network weights\n",
    "!git clone https://gin.g-node.org/walkerlab/fens-2022.git /content/trained_nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Slide presentation - A primer on computational neuroscience and system identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come back to complete the rest of the notebook after the slide presentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Developing models of neural population responses to natural images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have been primed with the goals of system identification, let's get our hands dirty by building our first neuronal response prediction model.\n",
    "\n",
    "As part of the setup, we have downloaded a 2-photon imaging dataset recorded from the mouse primary visual cortex, as we presented 1000s of natural images (note - if not done yet, please go back to  by Part 0 of this notebook to download the dataset).\n",
    "\n",
    "First thing first, let's go ahead and import a set of standard libraries that'll prove useful in exploring our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating the neuroscience data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with any data science project, you must start by understanding your data! Let's take some time to navigate the data you downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Explore the downloaded dataset by using either the file explorer to the left of the Colab/JupyterLab environment or via `ls` and `cd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You would see that both responses and images are contained in collections of `numpy` files named like `1.npy` or `31.npy`. The number here corresponds to a specific **trial** or simply different image presentation during an experiment.\n",
    "\n",
    "Let's take a look at some of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data files one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick some trial and load the image as well as the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_idx = 1100\n",
    "trial_image = np.load(f'./Lurz2020/static20457-5-9-preproc0/data/images/{trial_idx}.npy')\n",
    "trial_responses = np.load(f'./Lurz2020/static20457-5-9-preproc0/data/responses/{trial_idx}.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is shaped as $\\text{channel} \\times \\text{height} \\times \\text{width}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Inspect the loaded image and the corresponding neuronal responses (e.g. visualize the image stimulus). How many neurons are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of `trial_response` is simply the number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_responses.min() # responses are practically always >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_responses.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.hist(trial_responses, 100);\n",
    "ax.set_title('Neural activity over all neurons responding to an image')\n",
    "ax.set_xlabel('Neuron activity')\n",
    "ax.set_ylabel('Neuron counts')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see most neuron's responses stay very close to 0 - signifying no activity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can inspect the image and the corresponding neural population responses one image at a time, this is quite cumbersome and also impractical for use in network training. Fortunately, the `fens` package provides us with a convenience function that will help to load the entire dataset as PyTorch [dataloaders](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fens.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we prepare the dataloaders, we get to specify the **batch size**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = load_dataset(path = './Lurz2020/static20457-5-9-preproc0', batch_size=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns a dictionary consisting of three dataloaders for training, validation, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specifically look at the trainset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dataloaders['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of images can be checked as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader.sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect what it returns per batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, responses = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, you can see it returns a batch size of 60 images and responses for all neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar inspection can be done on the **validation** and **testing** dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images in validation set\n",
    "len(dataloaders['validation'].sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of images in test set\n",
    "len(dataloaders['test'].sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might think that we have a lot of images in test set, but this is because test set consists of repeated images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some additional trial information can be observed by accessing the underlying PyTorch dataset object and looking at the `trial_info`. Note that this is not part of the standard PyTorch dataset/dataloader interface, but rather a feature specifically provided by our `fens` library!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to the dataset object that underlies all dataloaders\n",
    "dataset = dataloaders['test'].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trials that are marked as \"test\" set\n",
    "test_trials = np.where(dataset.trial_info.tiers == 'test')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about the presented image for ALL trials\n",
    "image_ids = dataset.trial_info.frame_image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find IDs of all unique images presented during test trials\n",
    "unique_test_images = np.unique(image_ids[test_trials])\n",
    "unique_test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(unique_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the test set consists of 100 unique images, each repeated up to 10 times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at how a neuron responds to these repeated presentations of an identical image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# gather the responses to the repeated image presentations\n",
    "repeated_image_responses = []\n",
    "for unique_test_image_id in tqdm(unique_test_images):\n",
    "    repeated_image_trials = test_trials[image_ids[test_trials] == unique_test_image_id]\n",
    "    responses = np.stack([dataset[trial][1].cpu().numpy() for trial in repeated_image_trials])\n",
    "    repeated_image_responses.append((unique_test_image_id, responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = 3 # choose one neuron to inspect its responses\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "labels = []\n",
    "for i, (image_id, responses) in enumerate(repeated_image_responses[:20]):\n",
    "    ax.scatter(np.ones(len(responses)) * i, responses[:, neuron_idx], c='k', s=0.5)\n",
    "    labels.append(image_id)\n",
    "\n",
    "ax.set_xticks(range(len(labels)))\n",
    "ax.set_xticklabels(labels, rotation=60)\n",
    "ax.set_title(f'Neuron {neuron_idx} responses to repeated image presentations')\n",
    "ax.set_xlabel('Image IDs')\n",
    "ax.set_ylabel('Responses')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Take a look at the responses of other neurons. Can you also plot the \"mean\" response for each image? How about their standard deviation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean and stdev of responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that indeed a single neuron's responses vary widely even to repeated presentations of an identical stimulus!\n",
    "\n",
    "This so-called **noiseness** of neural responses make predicting the respones of the neurons to images fundamentally challenging and in fact makes it  essentially impossible to yield a perfect fit!\n",
    "\n",
    "Instead, we would often try to fit the **distribution of responses** the best we can, and we will briefly visit this point later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the neuronal responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully loaded the dataset and inspected its contents, it's time for us to start **modeling** the responses.\n",
    "\n",
    "We will start by building a very basic **Linear-Nonlinear model** - which is nothing more than a shallow neural network with single linear layer followed by an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcVMbaG9xXNY"
   },
   "source": [
    "## Linear-Nonlinear (LN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arguably one of the simplest models of a neuron's response to a stimulus is the **linear-nonlinear (LN) model**. \n",
    "\n",
    "Given an image $I \\in \\mathbb{R}^{h\\,\\times\\,w}$ where $h$ and $w$ are the height and the width of the image, respectively, let us collapse the image into a vector $x \\in \\mathbb{R}^{hw}$.\n",
    "\n",
    "A single neuron's response $r$ under linear-nonlinear model can then be expressed as:\n",
    "$$\n",
    "r = a(\\mathbf{w}^\\top x + b),\n",
    "$$\n",
    "where $\\mathbf{w} \\in \\mathbb{R}^{hw}$ and $b \\in \\mathbb{R}$ are **weight** and **bias**, and $a:\\mathbb{R}\\mapsto\\mathbb{R}$ is a scalar **activating function**.\n",
    "\n",
    "We can in fact extend to capture the responses of all $N$ neurons simultaneously as:\n",
    "\n",
    "$$\n",
    "\\mathbf{r} = a(\\mathbf{W} x + \\mathbf{b}),\n",
    "$$\n",
    "where $\\mathbf{r} \\in \\mathbb{R}^{N}$, $\\mathbf{W} \\in \\mathbb{R}^{N\\,\\times\\,hw}$ and $\\mathbf{b} \\in \\mathbb{R}^{N}$.\n",
    "\n",
    "Hence, each neuron weighs each pixel of the image according to the weight $\\mathbf{w}$ (corresopnds to a row of $\\mathbf{W}$) and thus characterizes how much the each neuron \"cares\" about a specific pixel.\n",
    "\n",
    "The weight $\\mathbf{w}$ can be thought of as a **filter** that's the same size as the image and is overlaid on top of the image to determine what pixel would contribute to the neuron's response. \n",
    "\n",
    "This *image filter* is typically referred to as the **receptive field** of the neuron!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nonlinear activation function $a(\\cdot)$ ensures, among other things, that the output of the network stays above 0. In fitting neuronal responses, we tend to use $a(x) = ELU(x) + 1$ where ELU (Exponential Linear Unit) is defined as follows:\n",
    "\n",
    "$$\n",
    "    ELU(x) = \n",
    "\\begin{cases}\n",
    "    e^x - 1, & x \\lt 0 \\\\\n",
    "    x,   & x \\ge 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ELU function\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "x = np.linspace(-2, 2)\n",
    "ax.plot(x, F.elu(torch.Tensor(x)))\n",
    "ax.axhline(0, c='r', ls='--')\n",
    "ax.set_xlabel(r'Input, $x$')\n",
    "ax.set_ylabel(r'Activation, $ELU(x)$')\n",
    "ax.set_ylim([-1, 3])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shift it by 1 to ensure it will always remain positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ELU+1 function\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "x = np.linspace(-2, 2)\n",
    "ax.plot(x, F.elu(torch.Tensor(x))+1)\n",
    "ax.axhline(0, c='r', ls='--')\n",
    "ax.axhline(0, c='r', ls='--')\n",
    "ax.set_xlabel(r'Input, $x$')\n",
    "ax.set_ylabel(r'Activation, $ELU(x) + 1$')\n",
    "ax.set_ylim([-1, 3.0])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, it can be seen that a linear-nonlinear (LN) model is nothing more than a single linear layer applied on a flattened image input, followed by a nonlinear activation function (i.e. $ELU(x)+1$). \n",
    "\n",
    "Now let's go ahead and implment our LN model in PyTorch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a simple network consisting of a linear layer followed by ELU + 1 activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Implement a simple Linear-Nonlinear network using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_height,\n",
    "        input_width,\n",
    "        n_neurons,\n",
    "        momentum=0.1,\n",
    "        init_std=1e-3,\n",
    "        gamma=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # initialize\n",
    "        \n",
    "        self.initialize()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # implement\n",
    "        pass\n",
    "\n",
    "    def initialize(self, std=None):\n",
    "        # implement\n",
    "        pass\n",
    "\n",
    "\n",
    "    def regularizer(self):\n",
    "        # implement\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! We have now designed our first model of the neuron's responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS**: notice that we used batch normalization (BN) layer right before the linear layer? This empirically helps to stabilize the training, allowing us to be not too sensitive to the weight and bias initialization. You could implement and train a LN network without such BN layer and you are encouraged to try! However if you do, be wary of the network weight initializations and the choice of learning rate during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a candidate model designed, it's time to train it. While we could use a standard set of optimizers as provided by PyTorch to implement our training routine, here, we are provided with a convenience function `train_model` that would handle a lot of the training boilerplate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fens.trainers import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critically, by default, `train_model` sets up the training based on **Poisson loss** and also perform early stopping based on **correlation** of the predicted neuronal responses with the actual neuronal responses on the **validation set**. Let's now talk briefly about our objective (loss) function of choice in training neuron response models - the Poisson loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical aside: Poisson Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How we are **actually** modeling the noisy neuronal responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of **Poisson loss** follows from the assumption that, *conditioned on the stimulus*, the neurons' responses follow an **independent Poisson** distribution. That is, given an input image $x$, the population response $\\mathbf{r}$ is distributed as:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{r} | x) = \\prod_i^N \\text{Poiss}(r_i; \\lambda_i(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $r_i$ is the $i^\\text{th}$ neuron in the population $\\mathbf{r}$. The $\\lambda_i$ is the parameter for Poisson distribution that controls its **average value**. Here we express $\\lambda_i(x)$ to indicate the fact that the average response for each neuron is expected to vary *as a function of the input image*. We can express this average matching as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[r_i|x] = \\lambda_i(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, it is precisely this function $\\lambda_i(x)$ that we are modeling using LN models and, in the next step, more complex neural networks. In otherwords, we are learning $\\lambda_i(x) = f_i(x, \\theta)$, where $\\theta$ is the trainable parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all together, this means that, our model $f(x, \\theta)$ is really modeling the average activity of the neurons,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[\\mathbf{r}|x] = \\mathbf{f}(x, \\theta)\n",
    "$$\n",
    "\n",
    "while we are assuming that the neurons are distributed according to **independent Poisson** distribution around the average responses predicted by our model $\\mathbf{f}(x, \\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deriving the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson distribution is defined as follows:\n",
    "\n",
    "$$\n",
    "p(r) = \\text{Poiss}(r; \\lambda) = \\frac{e^{-\\lambda}\\lambda^{r}}{r!}\n",
    "$$\n",
    "\n",
    "During the training, we would want to adjust the model parameter $\\theta$ to maximize the chance of observing the response $\\mathbf{r}$ to a known image $x$. This is achieved by **maximizing** the log-likelihood function $\\log p(\\mathbf{r}|x, \\theta)$, or equivalently by **minimzing the negative log-likelihood function** as the objective function $L(x, \\mathbf{r}, \\theta)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(x, \\mathbf{r}, \\theta) &= -\\log p(\\mathbf{r}|x, \\theta) \\\\\n",
    "&= -\\log \\prod_i \\text{Poiss}(r_i; f_i(x, \\theta)) \\\\\n",
    "&= -\\sum_i \\log \\frac{e^{-f_i(x, \\theta)}f_i(x, \\theta)^{r_i}}{r_i!} \\\\\n",
    "&= \\sum_i \\left(f_i(x, \\theta) - r_i \\log f_i(x, \\theta) + \\log r_i! \\right)\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the optimization, we seek for $\\theta$ that would minimize the loss $L$. Note that since the term $\\log r_i!$ does not depend on $\\theta$, it can be safely dropped from Poisson loss. Hence you would commonly see the following expression as the definition of the **Poisson loss**\n",
    "\n",
    "$$\n",
    "L_\\text{Poiss}(x, \\mathbf{r}, \\theta) = \\sum_i \\left(f_i(x, \\theta) - r_i \\log f_i(x, \\theta)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing the training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the theoretical foundation for the training and the choice of the objective function under our belt, let's go ahead and train the network. Because the function `train_model` handles a lot underneath the hood, training a model is just as easy as invoking the function by passing it the model to be trained and the dataloaders!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, let's instantiate the model to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln_model = Linear(input_height=64, input_width=36, n_neurons=5335, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fens.trainers import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnIjtCeERCjk",
    "outputId": "569f4934-9cb5-4253-ae02-001b6a9d7828"
   },
   "outputs": [],
   "source": [
    "score, output, model_state = train_model(model=ln_model, dataloader=dataloaders, device='cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! We have now successfully trained our very first LN model on real neuronal responses! But really, how good is the model?\n",
    "\n",
    "During the training, the `train_model` function iteratively reported two values: the loss function (Poisson loss) value and the average correlation. \n",
    "\n",
    "But what is this correlation? It's simply the correlation computed between our predicted neuronal responses $\\hat{r}_i$ and the actual neuronal responses $r_i$ across images in the validation set. We then take the average correlation value **across neurons** to get average correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being a correlation, the highest possible value is of course 1.0. Practically speaking, this is never reached both due to 1) imperfection of our model and more fundamentally due to 2) the noiseness of the neuron's responses. Because of the noise, even a perfect model would never reach a correlation of 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's actually go ahead and look at the model's predicted responses on the **test set** and compare them against the actual responses.\n",
    "\n",
    "The package `fens` provides for a convenient function to quickly gather the model's responses and the actual responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fens.utility import measures\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# here we evaluate the performance of the model on the test set\n",
    "actual_responses, model_responses = measures.model_predictions(ln_model, dataloaders['test'], device='cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Plot the predicted vs the actual responses to see how good our model performed. Also, compute and display Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted (model) vs real neurons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at how this correlation is distributed across neurons. This time, we'll use `get_gorrelations` function to compute correation for all neurons quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation on test set\n",
    "ln_test_correlations = measures.get_correlations(\n",
    "    ln_model, dataloaders[\"test\"], device=\"cuda\", per_neuron=True\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "n, bins, _ = ax.hist(ln_test_correlations, bins=100, color='k')\n",
    "mean_corr = np.mean(ln_test_correlations)\n",
    "ax.axvline(mean_corr, color=\"r\")\n",
    "ax.text(\n",
    "    x=mean_corr + 0.01,\n",
    "    y=np.max(n),\n",
    "    s=\"mean = {:.3f}\".format(mean_corr),\n",
    ")\n",
    "ax.set_title('Testset correlation of LN model')\n",
    "ax.set_xlabel('Correlation')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that value of achieved correlation on the test set widely varies among the neurons. Some neurons are quite well predicted, reaching correlation above 0.6, where as many neurons have correlation well below 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going beyond Linear-Nonlinear model by using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that a simple LN model can be trained to achieve above chance performance in predicting the responses of mouse V1 neurons to natural images. But we certainly must be able to do better than that, right?\n",
    "\n",
    "In the past decade, what has really driven system identification of visual neurons has been the use of convolutional neural networks (CNN). Below, we will try out a very simple CNN to see if we can already reach better performance than LN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Implement a \"simple\" CNN to predict responses of neurons from images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_height,\n",
    "        input_width,\n",
    "        n_neurons,\n",
    "        momentum=0.1,\n",
    "        init_std=1e-3,\n",
    "        gamma=0.1,\n",
    "        hidden_channels=8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.init_std = init_std\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # CNN core\n",
    "        self.cnn_core = nn.Sequential(\n",
    "            # fill in\n",
    "        )\n",
    "\n",
    "        # Fully connected readout\n",
    "        self.readout = nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                   # fill in\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    def initialize(self, std=None):\n",
    "        if std is None:\n",
    "            std = self.init_std\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, std=std)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # fill in\n",
    "    \n",
    "    def regularizer(self):\n",
    "        return self.readout[0].weight.abs().sum() * self.gamma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now instantiate the model and train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CNN(input_height=64, input_width=36, n_neurons=5335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, output, model_state = train_model(model=cnn_model, dataloader=dataloaders, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation on test set\n",
    "cnn_test_correlations = measures.get_correlations(\n",
    "    cnn_model, dataloaders[\"test\"], device=\"cuda\", per_neuron=True\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "n, bins, _ = ax.hist(cnn_test_correlations, bins=100, color='k')\n",
    "mean_corr = np.mean(cnn_test_correlations)\n",
    "ax.axvline(mean_corr, color=\"r\")\n",
    "ax.text(\n",
    "    x=mean_corr + 0.01,\n",
    "    y=np.max(n),\n",
    "    s=\"mean = {:.3f}\".format(mean_corr),\n",
    ")\n",
    "ax.set_title('Testset correlation of CNN model')\n",
    "ax.set_xlabel('Correlation')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So on average, it seems to do better than our simple LN model. Let's compare the performance for each neuron between the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Compare the performance of the LN vs CNN models by plotting the correlation performance of both models for each neuron separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare model performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here each dot corresponds to a single neuron, plotting the LN vs CNN model's performance in predicting that neuron's responses. Red diagonal establishes the equal performance line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can appreciate that for vast majority of neurons (each black point), the CNN model yields better predictive performance than the LN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out the State-of-the-Art (SOTA) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we got some sense on how we could go about training linear and nonlinear network models to predict V1 neuron responses to natural images, and we just saw how using a CNN model brings significant improvement to the performance beyond the LN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might now be wondering, how good can we get? To get a sense of this, let's go ahead and train a state-of-the-art (SOTA) CNN model for mouse V1 responses to natual images as published in our recent work in [Lurz et al. ICLR 2021](https://github.com/sinzlab/Lurz_2020_code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, I have provided for the network implementation in the `fens` package, so you can build the model just by invoking a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fens.models import build_lurz2020_model\n",
    "\n",
    "# configuration for the model. Values are taken from the paper.\n",
    "model_config = {'init_mu_range': 0.55,\n",
    "                'init_sigma': 0.4,\n",
    "                'input_kern': 15,\n",
    "                'hidden_kern': 13,\n",
    "                'gamma_input': 1.0,\n",
    "                'grid_mean_predictor': {'type': 'cortex',\n",
    "                                        'input_dimensions': 2,\n",
    "                                        'hidden_layers': 0,\n",
    "                                        'hidden_features': 0,\n",
    "                                        'final_tanh': False},\n",
    "                'gamma_readout': 2.439\n",
    "               }\n",
    "\n",
    "sota_cnn_model = build_lurz2020_model(**model_config, dataloaders=dataloaders, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line to train the network instead\n",
    "#score, output, model_state = train_model(model=sota_cnn_model, dataloader=dataloaders, device='cuda')\n",
    "\n",
    "state_dict = torch.load(\"./FENS-2022/trained_nets/sota_cnn_model_state.pt\")\n",
    "sota_cnn_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's take a look at the testset performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation on test set\n",
    "sota_cnn_test_correlations = measures.get_correlations(\n",
    "    sota_cnn_model, dataloaders[\"test\"], device=\"cuda\", per_neuron=True\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "n, bins, _ = ax.hist(sota_cnn_test_correlations, bins=100, color='k')\n",
    "mean_corr = np.mean(sota_cnn_test_correlations)\n",
    "ax.axvline(mean_corr, color=\"r\")\n",
    "ax.text(\n",
    "    x=mean_corr + 0.01,\n",
    "    y=np.max(n),\n",
    "    s=\"mean = {:.3f}\".format(mean_corr),\n",
    ")\n",
    "ax.set_title('Testset correlation of SOTA CNN model')\n",
    "ax.set_xlabel('Correlation')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that we can have a *linearized* version of the SOTA model. This effectively removes all nonlinear operations within the network except for the very last nonlinear activation, rendering the network into a **LN model** but with more complex architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model_config = dict(model_config) # copy the config\n",
    "linear_model_config['linear'] = True # set linear to True to make it a LN model!\n",
    "\n",
    "sota_ln_model = build_lurz2020_model(**linear_model_config, dataloaders=dataloaders, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line to train the network instead\n",
    "#score, output, model_state = train_model(model=sota_ln_model, dataloader=dataloaders, device='cuda')\n",
    "\n",
    "state_dict = torch.load(\"./FENS-2022/trained_nets/sota_ln_model_state.pt\")\n",
    "sota_ln_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute correlation on test set\n",
    "sota_ln_test_correlations = measures.get_correlations(\n",
    "    sota_ln_model, dataloaders[\"test\"], device=\"cuda\", per_neuron=True\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "n, bins, _ = ax.hist(sota_ln_test_correlations, bins=100, color='k')\n",
    "mean_corr = np.mean(sota_ln_test_correlations)\n",
    "ax.axvline(mean_corr, color=\"r\")\n",
    "ax.text(\n",
    "    x=mean_corr + 0.01,\n",
    "    y=np.max(n),\n",
    "    s=\"mean = {:.3f}\".format(mean_corr),\n",
    ")\n",
    "ax.set_title('Testset correlation of SOTA LN model')\n",
    "ax.set_xlabel('Correlation')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, you can see that compared to our simple LN model, the SOTA LN model actually attains much better performance. This, among other things, reflects the **ease of training** the CNN based network compared to our *fully-connected* simple linear model. Despite the architectural complexity of the SOTA LN model, it is still a LN model as was described mathematically as:\n",
    "\n",
    "$$\n",
    "\\mathbf{r} = a(\\mathbf{W} x + \\mathbf{b})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare model performance between SOTA CNN and SOTA LN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, let's compare the performanc of SOTA CNN vs SOTA LN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare model performance\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.scatter(sota_ln_test_correlations, sota_cnn_test_correlations, color=\"k\", s=1)\n",
    "ax.set_xlabel('SOTA LN correlation')\n",
    "ax.set_ylabel('SOTA CNN correlation')\n",
    "ax.set_title('SOTA LN vs CNN model performance comparison')\n",
    "ax.plot([0, 1], [0, 1], color='r')\n",
    "ax.axis('square')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that SOTA CNN model still performs better than the SOTA LN model across most of the neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the trained models to gain insights into the brain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained some models successfully with decent predictive performances, you might be wondering what can we do with these models?\n",
    "\n",
    "Ideally, we could use these models to gain insights into the modeled neurons, and even potentially derive new predictions that can then be tested with a new set of experiments.\n",
    "\n",
    "Let's first analyze the **gradient receptive field (RF)** of the modeled neurons to get a rough sense of what is it that each neuron is *looking for* in the image when they respond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Receptive Fields (RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider our simple linear-nonlinear (LN) model. Recall from above that for each neuron, the response of the model to an image $x$ can be captured as follows:\n",
    "\n",
    "$$\n",
    "r = a(\\mathbf{w}^\\top x + b)\n",
    "$$\n",
    "\n",
    "and I already mentioned that the $\\mathbf{w}$ can be thought of as a image filter that selects out pixels that the neuron cares about. This filter is typically referred to as the **receptive field** of the (LN) neuron.\n",
    "\n",
    "It can actually be seen that we can **compute** the receptive field $\\mathbf{w}$ by simply taking the **gradient of the response with respect to the input image**:\n",
    "\n",
    "$$\n",
    "\\nabla_x r = a^\\prime(\\mathbf{w}^\\top x + b) \\cdot \\mathbf{w}\n",
    "$$\n",
    "\n",
    "You could see that $a^\\prime(\\mathbf{w}^\\top x + b)$ is still a scalar function that will evalute to some scalar value, and therefore,\n",
    "\n",
    "$$\n",
    "\\nabla_x r \\propto \\mathbf{w}\n",
    "$$\n",
    "\n",
    "Therefore, you can compute the gradient of the model with respect to the input image to get the receptive field $\\mathbf{w}$ up to some scalar constant. This method of obtaining the receptive field is commonly referred to as the **gradient receptive field (RF)**.\n",
    "\n",
    "Note that for LN model, gradient RF correctly approximates the weight $\\mathbf{w}$. However when this is applied to more highly nonlinear models like CNNs, the gradient RF can be thought of as giving a locally linear approximation to the CNN model, and still provide some rough insight into what is it that each neuron is looking for when they respond to an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now go ahead and compute the gradient RF for our models. We will make use of the PyTorch automatic differentiation system to easily compute the gradient with respect to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DETAILS**: For LN model, it actually doesn't matter too much *where* you compute the gradient at (that is, what value of input image $x$ you will feed in). However the \"where\" can matter quite a bit more when evaluting gradient RF for highly nonlinear models such as our CNN model. For this reason, we are going to feed in an *average image* which will be a gray image with intensity set to the average value across all images in the training set. This value has been precomputed and provided as part of the `dataset` that underlies our data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a function that, when given a model, neuron index, and the image at which point you want to evaluate the gradient, returns the gradient RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grad_rf(model, neuron_idx, input_image, device=\"cuda\"):\n",
    "    assert input_image.ndim == 2\n",
    "    # prepare input image with requires_grad = True so that gradient will be computed\n",
    "    x = torch.tensor(\n",
    "        input_image.copy()[None, None, ...],\n",
    "        dtype=torch.float,\n",
    "        device=device,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    # be sure to put the model on eval mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # get the response of the target neuron\n",
    "    model_activation = model(x)[:, neuron_idx]\n",
    "    # compute gradient with respect to the input\n",
    "    model_activation.backward()\n",
    "    \n",
    "    # prepare the gradient RF\n",
    "    grad_rf = x.grad.data.cpu().numpy().squeeze()\n",
    "    return grad_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose input mean as starting point\n",
    "input_mean = dataset.statistics.images.all.mean\n",
    "input_std = dataset.statistics.images.all.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and genearte and visualize the grad RF for both our SOTA CNN and SOTA LN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select neuron to compute RFs\n",
    "neuron_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a gradient receptive field from the sota_model and the sota_ln_model\n",
    "input_image = np.zeros((36, 64)) + input_mean\n",
    "\n",
    "grad_rf_sota_cnn = generate_grad_rf(\n",
    "    sota_cnn_model, neuron_idx=neuron_idx, input_image=input_image\n",
    ")\n",
    "grad_rf_sota_ln = generate_grad_rf(\n",
    "    sota_ln_model, neuron_idx=neuron_idx, input_image=input_image\n",
    ")\n",
    "\n",
    "# visualize the two gradient RFs side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5), dpi=150)\n",
    "\n",
    "scale = np.max([np.max(np.abs(img)) for img in [grad_rf_sota_cnn, grad_rf_sota_ln]])\n",
    "\n",
    "axes[0].imshow(grad_rf_sota_cnn, cmap=\"gray\")\n",
    "axes[0].set_title(\"SOTA CNN model\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(grad_rf_sota_ln, cmap=\"gray\")\n",
    "axes[1].set_title(\"SOTA LN model\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "fig.suptitle(\"Gradient receptive fields\", y=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that, the gradient RF look grossly similar between the CNN model and LN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Explore the gradient RF for other neurons. Do you see the grad RF for CNN and LN differing significantly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Exciting Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have mentioned above, the gradient RF is a local linear approximation of the CNN model and could vary a lot when computed with different input image. To gain a global insight of the modeled neuron's feature selectivity, we will derive their **Most Exciting Inputs (MEIs)**.\n",
    "As the name implies, an MEI is the input $x$ that maximizes a specific modeled neuron's response. To generate the MEI for a targeted neuron $i$, we optimize the model-predicted activation $f_i$ with respect to the input image $x$, yielding:\n",
    "\n",
    "$$\n",
    "x_i = \\text{argmax}_x f_i(x, \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the SGD optimizer in PyTorch to solve this optimization problem. Since the optimization algorithms implemented in PyTorch are all designed to minimize the loss function, we use negative model activation as the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with modeled neurons that do not necessarily have a 'maximal firing rate' unlike the biological neurons, thus it is common to compute the MEIs with certain constraints to ensure $x$ maintains roughly in the input space that the model is trained on. A common approach is to fix the mean and standard deviation of $x$ during optimization at reasonable values. In the following experiment, we fix the mean at the mean of the training set and std at 1/10th of the std of the training set. Feel free to explore MEIs generated with different constraints!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input image used as the starting point of the optimization in theory should not affect the MEI if the optimization finds the global maximum every time and there exists only one maximum. Here, we chose an input image randomly initiated with a normal distibution. You are encouraged to try out different input images and explore the differences in the resulting MEIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_mei(\n",
    "    model,\n",
    "    input_image,\n",
    "    neuron_idx,\n",
    "    iterations,\n",
    "    mean_constr,\n",
    "    std_constr,\n",
    "    lr=1,\n",
    "    device=\"cuda\",\n",
    "    disable_progress_bar=False,\n",
    "):\n",
    "    assert input_image.ndim == 2\n",
    "    std_constr = torch.tensor(std_constr).to(device)\n",
    "    mean_constr = torch.tensor(mean_constr).to(device)\n",
    "\n",
    "    # be sure to put the model on eval mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    # prepare input image with requires_grad = True so that gradient will be computed\n",
    "    x = torch.tensor(\n",
    "        input_image.copy()[None, None, ...],\n",
    "        dtype=torch.float,\n",
    "        device=device,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.SGD([x], lr=lr, momentum=0.9)\n",
    "    model_activations = []\n",
    "    for i in tqdm(range(iterations), disable=disable_progress_bar):\n",
    "        # fix the mean and std of the input image\n",
    "        transformed_x = (x - x.mean()) / (x.std() + 1e-4) * std_constr + mean_constr  # 1e-4 is added to avoid division by zero\n",
    "        model_activation = model(transformed_x)[:, neuron_idx]\n",
    "        (-model_activation).backward()\n",
    "        model_activations.append(model_activation.detach().cpu().numpy())\n",
    "        optimizer.step()\n",
    "    # finally, reapply the mean and norm constrain on the image\n",
    "    x = (x - x.mean()) / (x.std() + 1e-4) * std_constr + mean_constr\n",
    "    return np.array(model_activations), x.detach().cpu().numpy().squeeze()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's go ahead and genearte the MEIs for both SOTA CNN and SOTA LN models for the same target neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a gradient receptive field from the sota_model and the sota_ln_model\n",
    "activation_sota_cnn, mei_sota_cnn = generate_mei(\n",
    "    sota_cnn_model,\n",
    "    input_image=np.random.normal(input_mean, 0.1, (36, 64)),\n",
    "    neuron_idx=neuron_idx,\n",
    "    iterations=2000,\n",
    "    mean_constr=input_mean,\n",
    "    std_constr=input_std / 10,\n",
    "    lr=100,\n",
    ")\n",
    "\n",
    "activation_sota_ln, mei_sota_ln = generate_mei(\n",
    "    sota_ln_model,\n",
    "    input_image=np.random.normal(input_mean, 0.1, (36, 64)),\n",
    "    neuron_idx=neuron_idx,\n",
    "    iterations=2000,\n",
    "    mean_constr=input_mean,\n",
    "    std_constr=input_std / 10,\n",
    "    lr=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and finally, let's take a look at the MEIs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the two meis\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 5), dpi=150)\n",
    "axes[0,0].imshow(mei_sota_cnn, cmap='gray')\n",
    "axes[0,0].axis('off')\n",
    "axes[0,0].set_title('SOTA CNN model')\n",
    "axes[1,0].plot(activation_sota_cnn)\n",
    "axes[1,0].set_ylabel('Model activation')\n",
    "axes[1,0].set_xlabel('Iterations')\n",
    "axes[0,1].imshow(mei_sota_ln, cmap='gray')\n",
    "axes[0,1].axis('off')\n",
    "axes[0,1].set_title('SOTA LN model')\n",
    "axes[1,1].plot(activation_sota_ln)\n",
    "axes[1,1].set_xlabel('Iterations')\n",
    "plt.suptitle('MEIs', y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEI cross activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we check how a neuron's MEI cross-activates other neurons. This will allow us to get a sense of how unique is each MEI, and potentially find a group of neurons that share similar MEIs. As it takes a long time to generate MEI, he we restrict ourselves to generate 5 MEIs and then compute cross activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick random 5 neurons\n",
    "neuron_idx_ls = [1, 48, 1092, 2008, 4029] # randomly selected 5 neurons\n",
    "meis = []\n",
    "for i in tqdm(neuron_idx_ls):\n",
    "    _, mei = generate_mei(\n",
    "            sota_cnn_model,\n",
    "            input_image=np.random.normal(input_mean, input_std / 10, (36, 64)),\n",
    "            neuron_idx=i,\n",
    "            iterations=500,\n",
    "            mean_constr=input_mean,\n",
    "            std_constr=input_std / 10,\n",
    "            disable_progress_bar=True,\n",
    "    )\n",
    "    meis.append(mei)\n",
    "\n",
    "meis = torch.tensor(np.stack(meis))[:, None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run MEIs through the network\n",
    "activations = sota_cnn_model(meis.cuda()).cpu().detach().numpy().squeeze()[:, neuron_idx_ls]\n",
    "\n",
    "# normalize activation by the heighest activation for each neuron\n",
    "activations = activations / activations.max(axis=0, keepdims=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, dpi=150)\n",
    "ax.imshow(activations, cmap='gray')\n",
    "ax.set_ylabel('MEIs')\n",
    "ax.set_xlabel('Neurons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRY IT OUT\n",
    "Explore MEIs of other neurons and their cross activations. Do you see any patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully trained DNN models of the V1 responses to natural images and even looked at how we can dig into the trained network to gain potential insights into the modeled systems by computing gradient RFs and MEIs.\n",
    "\n",
    "Now it's time for you to get wild and explore your own questions! Working in a group of 4-5 students, pick a project that involves a DNN model of the population responses. Below are some possible project directions you could base yours off of--or you could decide to take a completely novel direction!\n",
    "\n",
    "* In-silico experiments\n",
    "    * Having a well-trained DNN model opens up a lot of possibilities for performing so-called *in silico* experiments, where you could present any kind of stimulus to your model and characterize neurons' responses. Pick and find a paper with experiments that investigate/characterize V1 responses to stimulus, and replicate the study on your DNN model. Does your result agree with the finding from the paper on V1? If not, why do you think it fails to agree?\n",
    "* Improve the DNN model\n",
    "    * Starting with CNN model we built, consider how you would go about improving this network. Feel free to consult existing state-of-the-art networks. What do you think would be critical in improving your network performance?\n",
    "    * Throughout the whole training, we used Poisson loss. We already discussed how this is the same as assuming that neurons fire according to independent Poisson distribution. Is this a good assumption after all? If not, how could you go about improving on this? (Hint: consider different training loss/criterion. `train_model` can take in optional `loss` argument)\n",
    "* Exploring MEIs\n",
    "    * MEIs are very rich stimuli that seem to differ from the classic notion of V1 as a bank of Gabor filters. Can you group neurons based on \"similar\" MEIs?\n",
    "    * Some MEIs look more like RFs than others. Is there some underlying pattern to this?\n",
    "    * MEIs are images that are built to \"maximize\" the activation of the neurons. Can you come up with image(s) that optimize some other objective? What would it tell you about the neurons/population?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
